{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This command will prompt you for authorization\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Google Drive mounted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waid4xwrqa0C",
        "outputId": "537247d2-7865-4f28-d335-a350cb4cb6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the paths\n",
        "# This is the path to the zip file you uploaded\n",
        "zip_file_path = \"/content/drive/MyDrive/Indoor_air_quality.zip\"\n",
        "\n",
        "# This is where we'll unzip the first file\n",
        "temp_unzip_path = \"/content/drive/MyDrive/temp_dataset_folder/\"\n",
        "\n",
        "# This is the path to the *inner* zip file (based on our previous attempts)\n",
        "inner_zip_path = os.path.join(temp_unzip_path, \"aq_dataset.zip\")\n",
        "\n",
        "# This is the final destination for all your JSON files\n",
        "final_json_path = \"/content/drive/MyDrive/aq_dataset_unzipped/\"\n",
        "\n",
        "# Create the directories\n",
        "os.makedirs(temp_unzip_path, exist_ok=True)\n",
        "os.makedirs(final_json_path, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    # --- First Unzip ---\n",
        "    print(f\"Starting to unzip {zip_file_path}...\")\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "        z.extractall(temp_unzip_path)\n",
        "    print(f\"First unzip complete. Files are in {temp_unzip_path}\")\n",
        "\n",
        "    # --- Second Unzip ---\n",
        "    if os.path.exists(inner_zip_path):\n",
        "        print(f\"Found inner zip file: {inner_zip_path}. Unzipping now...\")\n",
        "        with zipfile.ZipFile(inner_zip_path, 'r') as z:\n",
        "            z.extractall(final_json_path)\n",
        "        print(f\"All JSON files are now in: {final_json_path}\")\n",
        "\n",
        "        # Clean up the temporary folder\n",
        "        # os.remove(inner_zip_path)\n",
        "        # os.rmdir(temp_unzip_path)\n",
        "        print(\"Cleanup of temp files complete.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"ERROR: Could not find 'aq_dataset.zip' inside the main zip.\")\n",
        "        print(\"Please check the contents of 'Indoor_air_quality.zip'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {zip_file_path}\")\n",
        "    print(\"Please make sure the file name is correct and it's in 'My Drive'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG8zi2YAq0XW",
        "outputId": "276143f4-fa29-41cb-8b2c-eea305861041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to unzip /content/drive/MyDrive/Indoor_air_quality.zip...\n",
            "First unzip complete. Files are in /content/drive/MyDrive/temp_dataset_folder/\n",
            "ERROR: Could not find 'aq_dataset.zip' inside the main zip.\n",
            "Please check the contents of 'Indoor_air_quality.zip'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import gc\n",
        "\n",
        "# This is the path where you unzipped the files\n",
        "json_folder_path = \"/content/drive/MyDrive/aq_dataset_unzipped/\"\n",
        "json_files = glob.glob(f\"{json_folder_path}/*.json\")\n",
        "\n",
        "# --- THIS IS THE KEY ---\n",
        "# We MUST include the 'time' column to resample\n",
        "columns_we_need = [\n",
        "    'time',            # <-- The most important column\n",
        "    'temperature',\n",
        "    'humidity',\n",
        "    'MQ7_CO_ppm',      # Model 1\n",
        "    'MQ135_CO',        # Model 1\n",
        "    'MQ9_CH4_ppm',     # Model 2\n",
        "    'CH4'              # Model 2\n",
        "]\n",
        "\n",
        "if not json_files:\n",
        "    print(f\"ERROR: No .json files found in {json_folder_path}\")\n",
        "else:\n",
        "    print(f\"Found {len(json_files)} JSON files. Loading and filtering...\")\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    for f in json_files:\n",
        "        try:\n",
        "            print(f\"Processing {f}...\")\n",
        "            with open(f, 'r') as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "            df_temp = pd.DataFrame(data=data['values'], columns=data['columns'])\n",
        "\n",
        "            # --- MEMORY SAVING STEP ---\n",
        "            # Filter for *only* the columns we need (now 7)\n",
        "            df_filtered = df_temp[columns_we_need].copy()\n",
        "            df_list.append(df_filtered)\n",
        "\n",
        "            del data, df_temp, df_filtered\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {f}: {e}\")\n",
        "\n",
        "    # --- THIS IS THE NEW LOGIC ---\n",
        "    if df_list:\n",
        "        print(\"\\nAll files processed. Concatenating...\")\n",
        "\n",
        "        # We'll call this df_raw\n",
        "        df_raw = pd.concat(df_list, ignore_index=True)\n",
        "        del df_list\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Data combined. Now converting time and resampling...\")\n",
        "\n",
        "        # 1. Convert 'time' column to datetime objects\n",
        "        # This can take a minute\n",
        "        print(\"Converting 'time' column to datetime (this may take a while)...\")\n",
        "        df_raw['time'] = pd.to_datetime(df_raw['time'])\n",
        "\n",
        "        # 2. Set 'time' as the index\n",
        "        print(\"Setting time index...\")\n",
        "        df_raw.set_index('time', inplace=True)\n",
        "\n",
        "        # 3. Resample the data into 1-minute averages\n",
        "        # This will average all readings within each minute\n",
        "        print(\"Resampling data to 1-minute averages...\")\n",
        "        # 'T' stands for minute. We take the mean() of all values in that minute.\n",
        "        df_resampled = df_raw.resample('1T').mean()\n",
        "\n",
        "        print(f\"Original rows: {len(df_raw)}, Resampled rows: {len(df_resampled)}\")\n",
        "\n",
        "        # Clean up the huge raw dataframe\n",
        "        del df_raw\n",
        "        gc.collect()\n",
        "\n",
        "        # --- Model 1 (CO) DataFrame ---\n",
        "        print(\"\\n--- Processing CO Model Data ---\")\n",
        "        co_cols = ['MQ7_CO_ppm', 'MQ135_CO', 'temperature', 'humidity']\n",
        "        df_co = df_resampled[co_cols].copy()\n",
        "        print(f\"Resampled CO rows: {len(df_co)}\")\n",
        "        df_co.dropna(inplace=True) # Drop rows missing CO data\n",
        "        print(f\"Clean CO rows for training: {len(df_co)}\")\n",
        "        print(df_co.head())\n",
        "\n",
        "        # --- Model 2 (VOC) DataFrame ---\n",
        "        print(\"\\n--- Processing VOC Model Data ---\")\n",
        "        voc_cols = ['MQ9_CH4_ppm', 'CH4', 'temperature', 'humidity']\n",
        "        df_voc = df_resampled[voc_cols].copy()\n",
        "        print(f\"Resampled VOC rows: {len(df_voc)}\")\n",
        "        df_voc.dropna(inplace=True) # Drop rows missing VOC data\n",
        "        print(f\"Clean VOC rows for training: {len(df_voc)}\")\n",
        "        print(df_voc.head())\n",
        "\n",
        "        print(\"\\nSuccessfully created 'df_co' and 'df_voc'.\")\n",
        "        print(\"You can now run Step 5 and 6.\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nNo data was loaded. Please check the file paths and structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vKkdGYuJ-D",
        "outputId": "1c3fc2b9-8c70-42d5-ea40-f44b05df4f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13 JSON files. Loading and filtering...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2023-12-09_2023-12-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-01-01_2024-01-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-02-01_2024-02-29.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-03-01_2024-03-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-04-01_2024-04-30.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-05-01_2024-05-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-06-01_2024-06-30.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-07-01_2024-07-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-08-01_2024-08-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-09-01_2024-09-30.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-10-01_2024-10-31.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-11-01_2024-11-30.json...\n",
            "Processing /content/drive/MyDrive/aq_dataset_unzipped/2024-12-01_2024-12-09.json...\n",
            "\n",
            "All files processed. Concatenating...\n",
            "Data combined. Now converting time and resampling...\n",
            "Converting 'time' column to datetime (this may take a while)...\n",
            "Setting time index...\n",
            "Resampling data to 1-minute averages...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1630477892.py:73: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  df_resampled = df_raw.resample('1T').mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 12790707, Resampled rows: 528480\n",
            "\n",
            "--- Processing CO Model Data ---\n",
            "Resampled CO rows: 528480\n",
            "Clean CO rows for training: 519205\n",
            "                           MQ7_CO_ppm  MQ135_CO  temperature   humidity\n",
            "time                                                                   \n",
            "2023-12-09 00:00:00+00:00        69.0  3.927202    23.950000  33.025000\n",
            "2023-12-09 00:01:00+00:00        69.0  3.822472    24.200000  33.133333\n",
            "2023-12-09 00:02:00+00:00        64.0  4.219279    24.166667  33.133333\n",
            "2023-12-09 00:03:00+00:00        69.0  3.653514    24.166667  33.133333\n",
            "2023-12-09 00:04:00+00:00        63.0  4.219279    24.166667  33.133333\n",
            "\n",
            "--- Processing VOC Model Data ---\n",
            "Resampled VOC rows: 528480\n",
            "Clean VOC rows for training: 493506\n",
            "                           MQ9_CH4_ppm    CH4  temperature   humidity\n",
            "time                                                                 \n",
            "2023-12-09 00:00:00+00:00    10.437220  576.0    23.950000  33.025000\n",
            "2023-12-09 00:01:00+00:00    10.437220  575.0    24.200000  33.133333\n",
            "2023-12-09 00:02:00+00:00    10.041720  580.0    24.166667  33.133333\n",
            "2023-12-09 00:03:00+00:00     9.986344  560.0    24.166667  33.133333\n",
            "2023-12-09 00:04:00+00:00    10.494850  577.0    24.166667  33.133333\n",
            "\n",
            "Successfully created 'df_co' and 'df_voc'.\n",
            "You can now run Step 5 and 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "print(\"--- Training Model 1 (CO Calibration) ---\")\n",
        "\n",
        "# 1. Define our features (X) and target (y) from the 'df_co' DataFrame\n",
        "features_co = ['MQ7_CO_ppm', 'temperature', 'humidity']\n",
        "target_co = 'MQ135_CO'\n",
        "\n",
        "X_co = df_co[features_co]\n",
        "y_co = df_co[target_co]\n",
        "\n",
        "# 2. Create and train the model\n",
        "model_co = LinearRegression()\n",
        "model_co.fit(X_co, y_co)\n",
        "\n",
        "# 3. Get the formula!\n",
        "print(\"\\nModel training complete.\")\n",
        "print(\"The formula is: y = (A * MQ7_CO) + (B * temp) + (C * humid) + Intercept\\n\")\n",
        "\n",
        "# Get the coefficients (A, B, C)\n",
        "coeffs_co = model_co.coef_\n",
        "intercept_co = model_co.intercept_\n",
        "\n",
        "print(\"--- üìã COPY THESE VALUES FOR YOUR ESP32 ---\")\n",
        "print(f\"Coefficient A (for MQ7_CO_ppm): {coeffs_co[0]}\")\n",
        "print(f\"Coefficient B (for temperature): {coeffs_co[1]}\")\n",
        "print(f\"Coefficient C (for humidity):    {coeffs_co[2]}\")\n",
        "print(f\"Intercept:                       {intercept_co}\")\n",
        "print(\"------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg6nZFFJ16Cx",
        "outputId": "65c9b5e0-9bee-4848-80ca-4bf33ff4d8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Model 1 (CO Calibration) ---\n",
            "\n",
            "Model training complete.\n",
            "The formula is: y = (A * MQ7_CO) + (B * temp) + (C * humid) + Intercept\n",
            "\n",
            "--- üìã COPY THESE VALUES FOR YOUR ESP32 ---\n",
            "Coefficient A (for MQ7_CO_ppm): 0.2066745367379103\n",
            "Coefficient B (for temperature): -0.08439702297944282\n",
            "Coefficient C (for humidity):    0.004321370524230999\n",
            "Intercept:                       -8.055104846752645\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "print(\"--- Training Model 2 (VOC/CH4 Calibration) ---\")\n",
        "\n",
        "# 1. Define our features (X) and target (y) from the 'df_voc' DataFrame\n",
        "features_voc = ['MQ9_CH4_ppm', 'temperature', 'humidity']\n",
        "target_voc = 'CH4'\n",
        "\n",
        "X_voc = df_voc[features_voc]\n",
        "y_voc = df_voc[target_voc]\n",
        "\n",
        "# 2. Create and train the model\n",
        "model_voc = LinearRegression()\n",
        "model_voc.fit(X_voc, y_voc)\n",
        "\n",
        "# 3. Get the formula!\n",
        "print(\"\\nModel training complete.\")\n",
        "print(\"The formula is: y = (A * MQ9_CH4) + (B * temp) + (C * humid) + Intercept\\n\")\n",
        "\n",
        "# Get the coefficients (A, B, C)\n",
        "coeffs_voc = model_voc.coef_\n",
        "intercept_voc = model_voc.intercept_\n",
        "\n",
        "print(\"--- üìã COPY THESE VALUES FOR YOUR ESP32 ---\")\n",
        "print(f\"Coefficient A (for MQ9_CH4_ppm): {coeffs_voc[0]}\")\n",
        "print(f\"Coefficient B (for temperature): {coeffs_voc[1]}\")\n",
        "print(f\"Coefficient C (for humidity):    {coeffs_voc[2]}\")\n",
        "print(f\"Intercept:                       {intercept_voc}\")\n",
        "print(\"------------------------------------------\")"
      ],
      "metadata": {
        "id": "K317nFw12Wxm",
        "outputId": "a0ad9cec-2e97-4df4-b9a9-990e806e8516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Model 2 (VOC/CH4 Calibration) ---\n",
            "\n",
            "Model training complete.\n",
            "The formula is: y = (A * MQ9_CH4) + (B * temp) + (C * humid) + Intercept\n",
            "\n",
            "--- üìã COPY THESE VALUES FOR YOUR ESP32 ---\n",
            "Coefficient A (for MQ9_CH4_ppm): 22.68115496453869\n",
            "Coefficient B (for temperature): -40.81730199744914\n",
            "Coefficient C (for humidity):    -0.65953960607782\n",
            "Intercept:                       1811.870146951751\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Performance Report: Model 1 (CO Calibration) ---\")\n",
        "\n",
        "# Use our trained model (model_co) to make predictions on all the data\n",
        "y_pred_co = model_co.predict(X_co)\n",
        "\n",
        "# Calculate the metrics\n",
        "r2_co = r2_score(y_co, y_pred_co)\n",
        "mae_co = mean_absolute_error(y_co, y_pred_co)\n",
        "rmse_co = np.sqrt(mean_squared_error(y_co, y_pred_co))\n",
        "\n",
        "print(f\"\\nSuccessfully evaluated {len(y_co)} data points.\")\n",
        "print(\"\\n--- üìã COPY THESE METRICS ---\")\n",
        "print(f\"R-squared (R¬≤):   {r2_co:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_co:.4f} ppm\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_co:.4f} ppm\")\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzreKqXSQHwx",
        "outputId": "bcff7e8c-a7cb-4013-d930-0cb4f74b8ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Performance Report: Model 1 (CO Calibration) ---\n",
            "\n",
            "Successfully evaluated 519205 data points.\n",
            "\n",
            "--- üìã COPY THESE METRICS ---\n",
            "R-squared (R¬≤):   0.3777\n",
            "Mean Absolute Error (MAE): 2.2279 ppm\n",
            "Root Mean Squared Error (RMSE): 3.2616 ppm\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Performance Report: Model 2 (VOC/CH4 Calibration) ---\")\n",
        "\n",
        "# Use our trained model (model_voc) to make predictions on all the data\n",
        "y_pred_voc = model_voc.predict(X_voc)\n",
        "\n",
        "# Calculate the metrics\n",
        "r2_voc = r2_score(y_voc, y_pred_voc)\n",
        "mae_voc = mean_absolute_error(y_voc, y_pred_voc)\n",
        "rmse_voc = np.sqrt(mean_squared_error(y_voc, y_pred_voc))\n",
        "\n",
        "print(f\"\\nSuccessfully evaluated {len(y_voc)} data points.\")\n",
        "print(\"\\n--- üìã COPY THESE METRICS ---\")\n",
        "print(f\"R-squared (R¬≤):   {r2_voc:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_voc:.4f} ppm\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_voc:.4f} ppm\")\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhPKTEQsQQlD",
        "outputId": "d1a84f18-efff-426b-d0bd-6389d40d8200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Performance Report: Model 2 (VOC/CH4 Calibration) ---\n",
            "\n",
            "Successfully evaluated 493506 data points.\n",
            "\n",
            "--- üìã COPY THESE METRICS ---\n",
            "R-squared (R¬≤):   0.4114\n",
            "Mean Absolute Error (MAE): 183.4077 ppm\n",
            "Root Mean Squared Error (RMSE): 231.7250 ppm\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: Install Firebase Admin ---\n",
        "!pip install firebase-admin\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "import json\n",
        "import os\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Make sure this matches the filename you uploaded to Colab!\n",
        "KEY_FILE = 'service-account-key.json'\n",
        "COLLECTION_NAME = 'logs'\n",
        "ZIP_FILENAME = 'SCCAQM_Dataset_Final.zip'\n",
        "EXPORT_DIR = 'temp_logs_export'\n",
        "\n",
        "# --- STEP 2: Initialize & Authenticate ---\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(KEY_FILE)\n",
        "    firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()\n",
        "\n",
        "print(\"‚úÖ Authentication Successful.\")\n",
        "\n",
        "# --- STEP 3: Download & Zip ---\n",
        "if not os.path.exists(EXPORT_DIR):\n",
        "    os.makedirs(EXPORT_DIR)\n",
        "\n",
        "print(f\"‚è≥ Downloading documents from '{COLLECTION_NAME}'...\")\n",
        "docs = db.collection(COLLECTION_NAME).stream()\n",
        "\n",
        "count = 0\n",
        "with zipfile.ZipFile(ZIP_FILENAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for doc in docs:\n",
        "        data = doc.to_dict()\n",
        "\n",
        "        # Convert timestamps to strings so they are readable in JSON\n",
        "        for key, value in data.items():\n",
        "            if hasattr(value, 'isoformat'):  # Check if it's a datetime object\n",
        "                data[key] = value.isoformat()\n",
        "\n",
        "        # Create a filename for this log (using the document ID)\n",
        "        json_filename = f\"{doc.id}.json\"\n",
        "\n",
        "        # Save to the zip file directly (writing data as a string)\n",
        "        zipf.writestr(json_filename, json.dumps(data, indent=4))\n",
        "\n",
        "        count += 1\n",
        "        if count % 1000 == 0:\n",
        "            print(f\"   Processed {count} logs...\")\n",
        "\n",
        "print(f\"\\nüéâ SUCCESS! Download complete.\")\n",
        "print(f\"üìä Total Records: {count}\")\n",
        "print(f\"üì¶ File created: {ZIP_FILENAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QpDhXKAsG_q",
        "outputId": "d5e7ff01-203e-433c-d674-0a39bb1a81e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firebase-admin in /usr/local/lib/python3.12/dist-packages (6.9.0)\n",
            "Requirement already satisfied: cachecontrol>=0.12.14 in /usr/local/lib/python3.12/dist-packages (from firebase-admin) (0.14.4)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.12/dist-packages (from firebase-admin) (2.187.0)\n",
            "Requirement already satisfied: google-cloud-storage>=1.37.1 in /usr/local/lib/python3.12/dist-packages (from firebase-admin) (3.6.0)\n",
            "Requirement already satisfied: pyjwt>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.5.0->firebase-admin) (2.10.1)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]==0.28.1->firebase-admin) (0.28.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=1.22.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-firestore>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from firebase-admin) (2.21.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (3.11)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]==0.28.1->firebase-admin) (4.3.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from cachecontrol>=0.12.14->firebase-admin) (2.32.4)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from cachecontrol>=0.12.14->firebase-admin) (1.1.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.43.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.71.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (4.2.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-firestore>=2.19.0->firebase-admin) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (1.7.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.5.0->firebase-admin) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin) (2.0.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (4.15.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]==0.28.1->firebase-admin) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]==0.28.1->firebase-admin) (4.1.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.7.8->firebase-admin) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.14->firebase-admin) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.14->firebase-admin) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.6.1)\n",
            "‚úÖ Authentication Successful.\n",
            "‚è≥ Downloading documents from 'logs'...\n",
            "   Processed 1000 logs...\n",
            "\n",
            "üéâ SUCCESS! Download complete.\n",
            "üìä Total Records: 1312\n",
            "üì¶ File created: SCCAQM_Dataset_Final.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "ZIP_FILE_NAME = 'SCCAQM_Dataset_Final.zip'\n",
        "\n",
        "# --- EXTRACT AND PROCESS ---\n",
        "data_list = []\n",
        "\n",
        "print(\"‚è≥ Reading dataset... this may take a moment.\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(ZIP_FILE_NAME, 'r') as z:\n",
        "        file_list = z.namelist()\n",
        "\n",
        "        # Filter only JSON files\n",
        "        json_files = [f for f in file_list if f.endswith('.json')]\n",
        "\n",
        "        print(f\"üìÑ Found {len(json_files)} JSON logs.\")\n",
        "\n",
        "        for filename in json_files:\n",
        "            with z.open(filename) as f:\n",
        "                try:\n",
        "                    entry = json.load(f)\n",
        "                    data_list.append(entry)\n",
        "                except Exception as e:\n",
        "                    print(f\"Skipping bad file {filename}: {e}\")\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data_list)\n",
        "\n",
        "    # --- CLEANING (THE FIX IS HERE) ---\n",
        "    # We use format='mixed' to handle timestamps that might look different\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], format='mixed')\n",
        "        df = df.sort_values('timestamp')\n",
        "\n",
        "    # --- GENERATE REPORT ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      DATASET STATISTICAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # 1. Temporal Coverage\n",
        "    print(f\"\\n--- 1. TEMPORAL COVERAGE ---\")\n",
        "    if 'timestamp' in df.columns:\n",
        "        start_date = df['timestamp'].min()\n",
        "        end_date = df['timestamp'].max()\n",
        "        duration = end_date - start_date\n",
        "        print(f\"Start Date: {start_date}\")\n",
        "        print(f\"End Date:   {end_date}\")\n",
        "        print(f\"Duration:   {duration}\")\n",
        "    else:\n",
        "        print(\"No 'timestamp' column found.\")\n",
        "\n",
        "    # 2. Volume\n",
        "    print(f\"\\n--- 2. DATA VOLUME ---\")\n",
        "    print(f\"Total Records (Instances): {len(df)}\")\n",
        "    print(f\"Total Columns (Attributes): {len(df.columns)}\")\n",
        "    print(f\"Attribute Names: {list(df.columns)}\")\n",
        "\n",
        "    # 3. Sensor Statistics (Numerical)\n",
        "    print(f\"\\n--- 3. ATTRIBUTE STATISTICS (Numerical) ---\")\n",
        "\n",
        "    # We explicitly look for your specific columns\n",
        "    target_cols = ['T_C', 'RH_Pct', 'Calibrated_CO', 'Calibrated_VOC', 'Heat_Index', 'MQ7_Raw', 'MQ9_Raw']\n",
        "    existing_cols = [c for c in target_cols if c in df.columns]\n",
        "\n",
        "    if existing_cols:\n",
        "        # round to 2 decimal places for cleaner reading\n",
        "        stats = df[existing_cols].describe().T[['min', 'max', 'mean', 'std']].round(2)\n",
        "        print(stats)\n",
        "    else:\n",
        "        print(\"Could not find standard sensor columns. Printing all numeric stats:\")\n",
        "        print(df.describe().T[['min', 'max', 'mean', 'std']].round(2))\n",
        "\n",
        "    # 4. Categorical Distribution\n",
        "    print(f\"\\n--- 4. CATEGORICAL DISTRIBUTIONS ---\")\n",
        "    if 'ML_Diagnosis' in df.columns:\n",
        "        print(\"\\nDiagnosis Counts:\")\n",
        "        print(df['ML_Diagnosis'].value_counts())\n",
        "\n",
        "    if 'systemMode' in df.columns:\n",
        "        print(\"\\nSystem Mode Counts:\")\n",
        "        print(df['systemMode'].value_counts())\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"PLEASE COPY THE CONTENT ABOVE THIS LINE\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Could not find '{ZIP_FILE_NAME}'. Please upload it to Colab.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tONwgVYayB8g",
        "outputId": "229f5b15-d70c-4cc8-e8f3-8c54df57194b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Reading dataset... this may take a moment.\n",
            "üìÑ Found 1312 JSON logs.\n",
            "\n",
            "========================================\n",
            "      DATASET STATISTICAL REPORT      \n",
            "========================================\n",
            "\n",
            "--- 1. TEMPORAL COVERAGE ---\n",
            "Start Date: 2025-11-14 05:12:47.599000+00:00\n",
            "End Date:   2025-11-19 10:13:01.500000+00:00\n",
            "Duration:   5 days 05:00:13.901000\n",
            "\n",
            "--- 2. DATA VOLUME ---\n",
            "Total Records (Instances): 1312\n",
            "Total Columns (Attributes): 11\n",
            "Attribute Names: ['Comfort_Metric', 'CO_PPM_ML', 'Flame_Alert', 'ML_Diagnosis', 'RH_Pct', 'T_C', 'VOC_PPM_ML', 'Shock_Mode', 'timestamp', 'Shock_Event', 'Actuator_State']\n",
            "\n",
            "--- 3. ATTRIBUTE STATISTICS (Numerical) ---\n",
            "         min   max   mean   std\n",
            "T_C     25.1  28.3  26.89  0.86\n",
            "RH_Pct  63.3  95.6  83.51  9.73\n",
            "\n",
            "--- 4. CATEGORICAL DISTRIBUTIONS ---\n",
            "\n",
            "Diagnosis Counts:\n",
            "ML_Diagnosis\n",
            "Normal             1268\n",
            "Flame_Alert          43\n",
            "Intrusion_Alert       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "========================================\n",
            "PLEASE COPY THE CONTENT ABOVE THIS LINE\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}